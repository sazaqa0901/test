{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sazaqa0901/test/blob/main/deepfake_resnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-중간발표 전에 짠 코드\n",
        "-데이터 분할 동욱이가 짠 코드 썼어"
      ],
      "metadata": {
        "id": "6gBsTpziKGxe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1XotsOdEnCB",
        "outputId": "3dbf8e3d-3c72-4d23-c011-1418ae740d65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "c9WXB16KEvPe"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "zip_file_name = '/content/drive/MyDrive/기학기/Dataset.zip'\n",
        "extraction_dir = '/content/dataset'\n",
        "\n",
        "with zipfile.ZipFile(zip_file_name, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extraction_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Vq0hqTg9Epaj"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import (GlobalAveragePooling2D, Dense, Dropout)\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "gIcXaA-JE3s6"
      },
      "outputs": [],
      "source": [
        "MODEL_SAVE_PATH = '/content/drive/MyDrive/기학기/best_alexnet_model.h5'\n",
        "face_real_dir = '/content/dataset/Dataset/Train/Real'\n",
        "face_fake_dir = '/content/dataset/Dataset/Train/Fake'\n",
        "\n",
        "real_paths = glob.glob(os.path.join(face_real_dir, \"*.*\"))\n",
        "fake_paths = glob.glob(os.path.join(face_fake_dir, \"*.*\"))\n",
        "\n",
        "all_paths = real_paths + fake_paths\n",
        "labels = [0] * len(real_paths) + [1] * len(fake_paths)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = 224\n",
        "EPOCHS = 20\n",
        "BATCH_SIZE = 64\n",
        "NUM_SAMPLES = 1000 # 사용할 총 샘플 수\n",
        "AUTOTUNE = tf.data.AUTOTUNE"
      ],
      "metadata": {
        "id": "PBaDRPq4JLhm"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "S3foyf-VE54p"
      },
      "outputs": [],
      "source": [
        " #--- 데이터 개수 샘플링 ---\n",
        "_, target_paths, _, target_labels = train_test_split(\n",
        "        all_paths, labels,\n",
        "        test_size=NUM_SAMPLES,\n",
        "        random_state=42,\n",
        "        stratify=labels\n",
        "    )\n",
        "# --- 7 : 3으로 분할 ---\n",
        "train_paths, temp_paths, train_labels, temp_labels = train_test_split(\n",
        "        target_paths, target_labels,\n",
        "        test_size=0.3,\n",
        "        random_state=42,\n",
        "        stratify=target_labels\n",
        "    )\n",
        "# --- 2 : 1로 분할 ---\n",
        "val_paths, test_paths, val_labels, test_labels = train_test_split(\n",
        "        temp_paths, temp_labels,\n",
        "        test_size=(1/3),\n",
        "        random_state=42,\n",
        "        stratify=temp_labels\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "RhD31Y_kE56S"
      },
      "outputs": [],
      "source": [
        "def load_and_resize_images(image_path, label):\n",
        "    image = tf.io.read_file(image_path)             #이미지 읽어오기\n",
        "    image = tf.image.decode_jpeg(image, channels=3) #jpg\n",
        "    image = tf.image.resize_with_pad(image, IMG_SIZE, IMG_SIZE) #resize+padding(이미지 비율 유지)\n",
        "    image = tf.cast(image, tf.float32) / 255.0      #정규화\n",
        "    return image, label\n",
        "\n",
        "#데이터 증강\n",
        "def data_augmentation(image, label):\n",
        "    image = tf.image.random_flip_left_right(image)               #좌우 반전\n",
        "    image = tf.image.random_brightness(image, max_delta=0.2)     #밝기 조절\n",
        "    image = tf.image.random_contrast(image, 0.8, 1.2)            #대비 조절\n",
        "    #image = tf.image.random_crop(image, size=[IMG_SIZE, IMG_SIZE, 3])  #무작위로 자르기\n",
        "    return image, label\n",
        "\n",
        "def create_dataset(paths, labels, is_training=True):\n",
        "    \"\"\"\n",
        "    이미지 경로 리스트로부터 tf.data.Dataset 파이프라인을 생성합니다.\n",
        "    \"\"\"\n",
        "    # 1. 경로 리스트로부터 데이터셋 생성\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((paths, labels))\n",
        "    # 2. 실시간 로드 및 전처리 (병렬 처리)\n",
        "    dataset = dataset.map(load_and_resize_images, num_parallel_calls=AUTOTUNE)\n",
        "    if is_training:\n",
        "        # 3. 학습용 데이터셋: 셔플 및 데이터 증강\n",
        "        dataset = dataset.shuffle(buffer_size=len(paths))\n",
        "        # 데이터 증강\n",
        "        dataset = dataset.map(data_augmentation, num_parallel_calls=AUTOTUNE)\n",
        "    # 4. 배치 나누기\n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "    # 5. Prefetch: GPU가 연산하는 동안 CPU가 다음 배치를 준비\n",
        "    dataset = dataset.prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "    return dataset\n",
        "\n",
        "train_ds = create_dataset(train_paths, train_labels, is_training=True)\n",
        "val_ds = create_dataset(val_paths, val_labels, is_training=False)\n",
        "test_ds = create_dataset(test_paths, test_labels, is_training=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrRvScCVFjk_",
        "outputId": "8a8c6699-9d0c-448c-8136-1c7591a505f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Epoch 1/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17s/step - accuracy: 0.4990 - loss: 0.8891 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 23s/step - accuracy: 0.4997 - loss: 0.8899 - val_accuracy: 0.5000 - val_loss: 0.6977\n",
            "Epoch 2/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 20s/step - accuracy: 0.5522 - loss: 0.7216 - val_accuracy: 0.5000 - val_loss: 0.6983\n",
            "Epoch 3/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17s/step - accuracy: 0.6426 - loss: 0.6594 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 21s/step - accuracy: 0.6420 - loss: 0.6601 - val_accuracy: 0.5150 - val_loss: 0.6926\n",
            "Epoch 4/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17s/step - accuracy: 0.6624 - loss: 0.6146 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 21s/step - accuracy: 0.6606 - loss: 0.6164 - val_accuracy: 0.5150 - val_loss: 0.6921\n",
            "Epoch 5/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18s/step - accuracy: 0.6588 - loss: 0.6094 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m248s\u001b[0m 22s/step - accuracy: 0.6607 - loss: 0.6077 - val_accuracy: 0.5350 - val_loss: 0.6907\n",
            "Epoch 6/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 21s/step - accuracy: 0.6635 - loss: 0.6290 - val_accuracy: 0.5000 - val_loss: 0.7033\n",
            "Epoch 7/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17s/step - accuracy: 0.7156 - loss: 0.5665 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 22s/step - accuracy: 0.7174 - loss: 0.5637 - val_accuracy: 0.5000 - val_loss: 0.6898\n",
            "Epoch 8/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17s/step - accuracy: 0.7340 - loss: 0.5271 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 21s/step - accuracy: 0.7331 - loss: 0.5283 - val_accuracy: 0.5200 - val_loss: 0.6881\n",
            "Epoch 9/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17s/step - accuracy: 0.6996 - loss: 0.5595 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 20s/step - accuracy: 0.7015 - loss: 0.5582 - val_accuracy: 0.5250 - val_loss: 0.6808\n",
            "Epoch 10/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 21s/step - accuracy: 0.7370 - loss: 0.5117 - val_accuracy: 0.5250 - val_loss: 0.7128\n",
            "Epoch 11/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17s/step - accuracy: 0.7487 - loss: 0.4651 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 21s/step - accuracy: 0.7499 - loss: 0.4642 - val_accuracy: 0.5850 - val_loss: 0.6518\n",
            "Epoch 12/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 21s/step - accuracy: 0.7866 - loss: 0.4538 - val_accuracy: 0.5300 - val_loss: 0.9474\n",
            "Epoch 13/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m249s\u001b[0m 20s/step - accuracy: 0.7252 - loss: 0.5236 - val_accuracy: 0.5300 - val_loss: 1.3009\n",
            "Epoch 14/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 21s/step - accuracy: 0.8090 - loss: 0.4043 - val_accuracy: 0.5250 - val_loss: 2.0173\n",
            "Epoch 15/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 21s/step - accuracy: 0.8065 - loss: 0.4525 - val_accuracy: 0.5400 - val_loss: 1.5894\n",
            "Epoch 16/20\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 21s/step - accuracy: 0.7802 - loss: 0.4134 - val_accuracy: 0.5850 - val_loss: 1.1123\n",
            "✅ 학습 완료!\n"
          ]
        }
      ],
      "source": [
        "#resnet\n",
        "base_model = ResNet50(\n",
        "    weights='imagenet',    #ImageNet 사전학습 가중치\n",
        "    include_top=False,     #분류층 제외함\n",
        "    input_shape=(224, 224, 3)\n",
        ")\n",
        "\n",
        "#사전학습된 가중치(나중에 fine-tuning?)\n",
        "#base_model.trainable = False\n",
        "\n",
        "#마지막 20~40 layers만 풀어서 재학습\n",
        "base_model.trainable = True\n",
        "for layer in base_model.layers[:-40]:\n",
        "    layer.trainable = False\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "output = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "#컴파일\n",
        "model.compile(\n",
        "    optimizer=RMSprop(learning_rate=le-4),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "#콜백\n",
        "callbacks = [ModelCheckpoint(MODEL_SAVE_PATH,\n",
        "                             monitor='val_loss',\n",
        "                             save_best_only=True,\n",
        "                             mode='min'),\n",
        "             EarlyStopping( #val_loss 개선X -> 학습 중단\n",
        "                            monitor='val_loss',\n",
        "                            patience=5,\n",
        "                            restore_best_weights=True)\n",
        "            ]\n",
        "\n",
        "#정확도 기준\n",
        "#EarlyStopping(\n",
        "#    monitor='val_accuracy',\n",
        "#    patience=5,\n",
        "#    mode='max',\n",
        "#    restore_best_weights=True,\n",
        "#)\n",
        "\n",
        "# 모델학습\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(\"✅ 학습 완료!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q74sIS0SG3O7",
        "outputId": "968f7778-bfd2-4cab-d43b-c09d06bd0af1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "저장된 모델 로드 성공.\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6s/step - accuracy: 0.6217 - loss: 0.6336\n",
            "\n",
            "===== 최종 테스트 결과 =====\n",
            "  Test Loss: 0.6430\n",
            "  Test Accuracy: 62.00%\n"
          ]
        }
      ],
      "source": [
        "# 테스트 평가\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "try:\n",
        "    best_model = load_model(MODEL_SAVE_PATH)\n",
        "    best_model.compile(optimizer='RMSprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    print(\"저장된 모델 로드 성공.\")\n",
        "    test_loss, test_accuracy = best_model.evaluate(test_ds)\n",
        "    print(f\"\\n===== 최종 테스트 결과 =====\")\n",
        "    print(f\"  Test Loss: {test_loss:.4f}\")\n",
        "    print(f\"  Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
        "except Exception as e:\n",
        "    print(f\"모델 로드 또는 평가 중 오류 발생: {e}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMaZAGqz2q5qEmCXn4o3UIC",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}